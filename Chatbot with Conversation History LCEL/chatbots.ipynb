{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Conversational History using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001DE269C2540>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001DE26B04E90>, model_name='gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"gemma2-9b-It\", groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Yash! ðŸ‘‹\\n\\nIt's great to meet you. Being a Data Scientist is awesome! What kind of projects are you working on these days?  \\n\\nDo you have any questions for me about data science, or anything else? I'm here to help! ðŸ˜Š \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 22, 'total_tokens': 83, 'completion_time': 0.110909091, 'prompt_time': 0.00015399, 'queue_time': 0.013471419, 'total_time': 0.111063081}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e85f87c6-a613-4024-8ab9-368c4613e08b-0', usage_metadata={'input_tokens': 22, 'output_tokens': 61, 'total_tokens': 83})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = \"Hii, I am Yash. I am a Data Sceintist\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Yash, and that you are a Data Scientist!  \\n\\nIs there anything else you'd like to tell me about yourself or your work?  I'm curious to learn more. ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 100, 'total_tokens': 149, 'completion_time': 0.089090909, 'prompt_time': 0.002506402, 'queue_time': 0.012826656, 'total_time': 0.091597311}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-23b259d7-243a-49f6-8ad2-5bc31a3977d9-0', usage_metadata={'input_tokens': 100, 'output_tokens': 49, 'total_tokens': 149})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hii, I am Yash. I am a Data Sceintist\"),\n",
    "        AIMessage(content = \"Hello Yash! ðŸ‘‹\\n\\nIt's great to meet you. Being a Data Scientist is awesome! What kind of projects are you working on these days?  \\n\\nDo you have any questions for me about data science, or anything else? I'm here to help! ðŸ˜Š \\n\\n\"),\n",
    "        HumanMessage(content = \"What is my name and what do I do?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our model is remembering out history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Associating Conversation History with SessionId**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\": \"chat1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Yash!  \\n\\nWhat kind of data science work do you do?  Are you working on any interesting projects right now? ðŸ˜Š \\n\\nI'm always eager to learn more about how people are using data science to make a difference.  \\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content= \"Hi my name is Yash, I am a Data Scientist\")],\n",
    "    config = config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Yash. ðŸ˜Š  \\n\\nI remember that you told me at the beginning of our conversation.  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 173, 'total_tokens': 199, 'completion_time': 0.047272727, 'prompt_time': 0.005363543, 'queue_time': 0.008265204, 'total_time': 0.05263627}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f330d6ef-e88d-4ba5-b3d6-9b3b5fc63b12-0', usage_metadata={'input_tokens': 173, 'output_tokens': 26, 'total_tokens': 199})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content= \"What is my name\")\n",
    "    ],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\": \"chat2\"\n",
    "    }\n",
    "}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
